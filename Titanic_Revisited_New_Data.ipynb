{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFpr, f_regression, f_classif\n",
    "# explicitly require this experimental feature\n",
    "from sklearn.experimental import enable_iterative_imputer  \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "SEED = 5678\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12) (418, 11)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(r'C:\\Users\\Me\\Kaggle\\Titanic_revisited\\data\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\Me\\Kaggle\\Titanic_revisited\\data\\test.csv')\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOLS Classifier\n",
    "> This is a custom classifier created using Scikit Learn's project template for custom estimators.\n",
    "> It uses statsmodels OLS for the initial fit. Predict then uses the same OLS model to make a \n",
    "> prediction. The median of the predictions is subtracted from the prediction to create an estimated \n",
    "> residual. The estimated residual is then divided by the standard deviation of the residuals from the fit\n",
    "> to create an estimated studentized residual. These studentized residuals are then tested against the\n",
    "> hyperparameter \"threshold\" to determine the label. All  values greater than or equal to the threshold are \n",
    "> labeled True, and values less than the threshold are labeled False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "class SOLSClassifier(BaseEstimator, ClassifierMixin ):\n",
    "    \n",
    "    def __init__(self, threshold = 'threshold', est_method = 'est_method'):\n",
    "        \n",
    "        #decision threshold of studentized residuals\n",
    "        self.threshold = threshold \n",
    "        self.est_method = est_method\n",
    "        np.random.seed(SEED)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y) \n",
    "        \n",
    "        #convert to df\n",
    "        self.X_ = pd.DataFrame(X)\n",
    "        self.y_ = pd.DataFrame(y)         \n",
    "        \n",
    "        #Fit OLS model\n",
    "        self.ols_mod = OLS(endog = self.y_, exog = self.X_)\n",
    "        self.ols_result = self.ols_mod.fit()\n",
    "        \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        # Check if fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "        \n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        X_n = pd.DataFrame(X)\n",
    "        \n",
    "        #OLS prediction       \n",
    "        prediction = self.ols_result.predict(X_n)        \n",
    "        \n",
    "        #calculate outlier and influence measures for OLS result\n",
    "        inf = OLSInfluence(self.ols_result)\n",
    "        \n",
    "        #Staandard Deviation of studentized residuals\n",
    "        std = inf.resid_std\n",
    "        \n",
    "        \"\"\"\n",
    "        Subtract the median of the predictions from the predictions to create an estimated residual.\n",
    "        Then divide the estiamted residual by the by the estimated standard deviation, the\n",
    "        standard deviation of the residuals from training, to create an estimated studentized residual.\n",
    "           \n",
    "        \"\"\" \n",
    "        # estimated residual\n",
    "        estimated_residual = prediction - np.nanmedian(prediction)\n",
    "        \n",
    "        #estiamted studentized residual\n",
    "        if self.est_method == 'mean':\n",
    "            stud_res = estimated_residual/np.nanmean(std)    #estimate using mean\n",
    "        if self.est_method == 'median':\n",
    "            stud_res = prediction/np.nanmedian(std)         #estimate using median\n",
    "        \n",
    "        #create predictions based on the threshold\n",
    "        self.preds = []        \n",
    "        for res in stud_res:\n",
    "            if res >= self.threshold:    \n",
    "                #self.preds.append(True)\n",
    "                self.preds.append(1)\n",
    "            else:\n",
    "                #self.preds.append(False)\n",
    "                self.preds.append(0)\n",
    "                \n",
    "        return self.preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "#Get classifier metrics, based on DAND\n",
    "def test_classifier(clf, dataset, feature_list, folds = 20):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    #data = np.array(dataset)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    sss = StratifiedShuffleSplit(n_splits = folds, random_state = SEED)\n",
    "    cv = sss.split(features, labels)\n",
    "    \n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print (\"Warning: Found a predicted label not == 0 or 1.\")\n",
    "                print (\"All predictions should take value 0 or 1.\")\n",
    "                print (\"Evaluating performance for processed predictions:\")\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print (clf)\n",
    "        print (PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5))\n",
    "        print (RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives))\n",
    "        print (\"\")\n",
    "    except:\n",
    "        print (\"Got a divide by zero when trying out:\", clf)\n",
    "        print (\"Precision or recall may be undefined due to a lack of true positive predicitons.\")\n",
    "\n",
    "\n",
    "#convert dictionary to numpy array of features, from DAND       \n",
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "    \n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print (\"error: key \", feature, \" not present\")\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "# prepares data for tester returns list and dict \n",
    "def tester_prep(dfn):\n",
    "    features_list = dfn.columns.values\n",
    "    data_dict = dfn.to_dict('index')\n",
    "    return features_list, data_dict\n",
    "\n",
    "#split FIRST row as labels, from DAND\n",
    "def targetFeatureSplit( data ):\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Columns\n",
    "train.drop(labels = [\"Name\", \"PassengerId\", \"Ticket\", \"Cabin\"], axis = 1, inplace = True)\n",
    "test.drop(labels = [\"Name\", \"PassengerId\", \"Ticket\", \"Cabin\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cols = train.columns\n",
    "train[cols] = train[cols].apply(pd.to_numeric, errors='coerce')\n",
    "test_cols = test.columns\n",
    "test[test_cols] = test[test_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,) (891, 7)\n"
     ]
    }
   ],
   "source": [
    "#Split to X,y\n",
    "X = train.copy()\n",
    "y = train['Survived'].copy()\n",
    "X.drop(['Survived'], axis = 1, inplace = True)\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.0      1      0   7.2500        S\n",
       "1       1  female  38.0      1      0  71.2833        C\n",
       "2       3  female  26.0      0      0   7.9250        S\n",
       "3       1  female  35.0      1      0  53.1000        S\n",
       "4       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7128, 15) (3344, 15)\n"
     ]
    }
   ],
   "source": [
    "# Create Dummies\n",
    "dummies = ['Pclass', 'Sex', 'Embarked']\n",
    "for dum in dummies:\n",
    "    train_dummies = pd.get_dummies(X[dum], prefix = [dum])\n",
    "    test_dummies = pd.get_dummies(test[dum], prefix = [dum])\n",
    "    X = pd.concat([X, train_dummies], axis = 0)\n",
    "    test = pd.concat([test, test_dummies], axis = 0)\n",
    "print(X.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>['Embarked']_C</th>\n",
       "      <th>['Embarked']_Q</th>\n",
       "      <th>['Embarked']_S</th>\n",
       "      <th>['Pclass']_1</th>\n",
       "      <th>['Pclass']_2</th>\n",
       "      <th>['Pclass']_3</th>\n",
       "      <th>['Sex']_female</th>\n",
       "      <th>['Sex']_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Embarked     Fare  Parch  Pclass     Sex  SibSp  ['Embarked']_C  \\\n",
       "0  22.0        S   7.2500    0.0     3.0    male    1.0             NaN   \n",
       "1  38.0        C  71.2833    0.0     1.0  female    1.0             NaN   \n",
       "2  26.0        S   7.9250    0.0     3.0  female    0.0             NaN   \n",
       "3  35.0        S  53.1000    0.0     1.0  female    1.0             NaN   \n",
       "4  35.0        S   8.0500    0.0     3.0    male    0.0             NaN   \n",
       "\n",
       "   ['Embarked']_Q  ['Embarked']_S  ['Pclass']_1  ['Pclass']_2  ['Pclass']_3  \\\n",
       "0             NaN             NaN           NaN           NaN           NaN   \n",
       "1             NaN             NaN           NaN           NaN           NaN   \n",
       "2             NaN             NaN           NaN           NaN           NaN   \n",
       "3             NaN             NaN           NaN           NaN           NaN   \n",
       "4             NaN             NaN           NaN           NaN           NaN   \n",
       "\n",
       "   ['Sex']_female  ['Sex']_male  \n",
       "0             NaN           NaN  \n",
       "1             NaN           NaN  \n",
       "2             NaN           NaN  \n",
       "3             NaN           NaN  \n",
       "4             NaN           NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Old Code\n",
    "> Some of this code is from a submission made over two years ago and I don't recall what is borrowed and what is original. If you see your code in this section, thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Improved Age Interpolation based on Pclass, Parch, Sibsp\n",
    "index_NaN_age = list(train[\"Age\"][train[\"Age\"].isnull()].index)\n",
    "\n",
    "for i in index_NaN_age :\n",
    "    age_med = train[\"Age\"].median()\n",
    "    age_pred = train[\"Age\"][((train['SibSp'] == train.iloc[i][\"SibSp\"]) & \n",
    "                             (train['Parch'] == train.iloc[i][\"Parch\"]) & \n",
    "                             (train['Pclass'] == train.iloc[i][\"Pclass\"]))].median()\n",
    "    if not np.isnan(age_pred) :\n",
    "        train['Age'].iloc[i] = age_pred\n",
    "    else :\n",
    "        train['Age'].iloc[i] = age_med\n",
    "        \n",
    "# Filling missing value of Age in test\n",
    "index_NaN_age = list(test[\"Age\"][test[\"Age\"].isnull()].index)\n",
    "\n",
    "for i in index_NaN_age :\n",
    "    age_med = test[\"Age\"].median()\n",
    "    age_pred = test[\"Age\"][((test['SibSp'] == test.iloc[i][\"SibSp\"]) & \n",
    "                            (test['Parch'] == test.iloc[i][\"Parch\"]) & \n",
    "                            (test['Pclass'] == test.iloc[i][\"Pclass\"]))].median()\n",
    "    if not np.isnan(age_pred) :\n",
    "        test['Age'].iloc[i] = age_pred\n",
    "    else :\n",
    "        test['Age'].iloc[i] = age_med\n",
    "\n",
    "#Add title variable\n",
    "dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in train[\"Name\"]]\n",
    "train[\"Title\"] = pd.Series(dataset_title)\n",
    "train[\"Title\"].head()\n",
    "\n",
    "dataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in test[\"Name\"]]\n",
    "test[\"Title\"] = pd.Series(dataset_title)\n",
    "test[\"Title\"].head()\n",
    "\n",
    "# Convert to categorical values Title train\n",
    "train[\"Title\"] = train[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "train[\"Title\"] = train[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n",
    "train[\"Title\"] = train[\"Title\"].astype(int)\n",
    "\n",
    "# Convert to categorical values Title test\n",
    "test[\"Title\"] = test[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "test[\"Title\"] = test[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n",
    "test[\"Title\"] = test[\"Title\"].astype(int)\n",
    "\n",
    "# Drop Name variable\n",
    "train.drop(labels = [\"Name\"], axis = 1, inplace = True)\n",
    "test.drop(labels = [\"Name\"], axis = 1, inplace = True)\n",
    "\n",
    "# Create a family size descriptor from SibSp and Parch\n",
    "\n",
    "train[\"Fsize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\n",
    "# Create new feature of family size\n",
    "train['Single'] = train['Fsize'].map(lambda s: 1 if s == 1 else 0)\n",
    "train['SmallF'] = train['Fsize'].map(lambda s: 1 if s == 2  else 0)\n",
    "train['MedF']   = train['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "train['LargeF'] = train['Fsize'].map(lambda s: 1 if s >= 5 else 0)\n",
    "\n",
    "test[\"Fsize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1\n",
    "test['Single'] = test['Fsize'].map(lambda s: 1 if s == 1 else 0)\n",
    "test['SmallF'] = test['Fsize'].map(lambda s: 1 if s == 2  else 0)\n",
    "test['MedF']   = test['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n",
    "test['LargeF'] = test['Fsize'].map(lambda s: 1 if s >= 5 else 0)\n",
    "\n",
    "\n",
    "# Create the column Child and assign to 'NaN'\n",
    "train[\"Child\"] = float('NaN')\n",
    "test[\"Child\"] = float('NaN')\n",
    "\n",
    "# Assign 1 to passengers < 20, 0 to those >= 20*******************************\n",
    "age_var = 11 #9\n",
    "train[\"Child\"][train[\"Age\"] < age_var] = 1\n",
    "train[\"Child\"][train[\"Age\"] >= age_var] = 0\n",
    "\n",
    "test[\"Child\"][test[\"Age\"] < age_var] = 1\n",
    "test[\"Child\"][test[\"Age\"] >= age_var] = 0\n",
    "\n",
    "# Convert male and female groups to integer form\n",
    "train[\"Sex\"][train[\"Sex\"] == \"male\"] = 0\n",
    "train[\"Sex\"][train[\"Sex\"] == \"female\"] = 1\n",
    "test[\"Sex\"][test[\"Sex\"] == \"male\"] = 0\n",
    "test[\"Sex\"][test[\"Sex\"] == \"female\"] = 1\n",
    "\n",
    "# Impute the Embarked variable\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "# Embarked to int\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"S\"] = 0\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"C\"] = 1\n",
    "train[\"Embarked\"][train[\"Embarked\"] == \"Q\"] = 2\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"S\"] = 0\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"C\"] = 1\n",
    "test[\"Embarked\"][test[\"Embarked\"] == \"Q\"] = 2\n",
    "\n",
    "test.Fare[152] = test.Fare.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for f in train.columns: \n",
    "    if train[f].dtype=='object': \n",
    "        lbl = preprocessing.LabelEncoder() \n",
    "        lbl.fit(list(train[f].values)) \n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        \n",
    "for f in test.columns: \n",
    "    if test[f].dtype=='object': \n",
    "       lbl = preprocessing.LabelEncoder() \n",
    "       lbl.fit(list(test[f].values)) \n",
    "       test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make survived the first column for tester\n",
    "train = train.reindex(columns=(['Survived'] + list([a for a in train.columns if a != 'Survived']) ))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ols pipe smt\n",
    "k = 14 #11\n",
    "smt = SMOTE(random_state = SEED)\n",
    "ols_m = SOLSClassifier(0.747, est_method = 'mean')  #82933 0.747, mean    82978 w/age 11\n",
    "#model = Pipeline([('fpr', SelectFpr()),  ('ols', ols_m)]) \n",
    "#model = Pipeline([  ('kBest', SelectKBest( f_classif,k = k)), ('ols', ols_m)])\n",
    "#model = Pipeline([ ('smt', smt),  ('ols', ols_m)])\n",
    "model = ols_m\n",
    "feat, dat = tester_prep(train)\n",
    "test_classifier(model, dat, feat, folds = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.copy()\n",
    "y = train['Survived'].copy()\n",
    "X.drop(['Survived'], axis = 1, inplace = True)\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "#Scoring Function**********************************************************************************\n",
    "def compute_score(clf, X, y, scoring='accuracy'):\n",
    "    xval = cross_val_score(clf, X, y, cv = 10, scoring=scoring)\n",
    "    return np.mean(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SOLSClassifier(0.747, est_method = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compute_score(clf, X, y, scoring='accuracy')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://machinelearningmastery.com/compare-machine-learning-algorithms-python-scikit-learn/\n",
    "models = []\n",
    "models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
    "#models.append(('GPC', GaussianProcessClassifier(1.0 * RBF(1.0),random_state = SEED)))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('DTC', DecisionTreeClassifier(random_state = SEED)))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('SVM', SVC(random_state = SEED)))\n",
    "models.append(('ABC', AdaBoostClassifier(random_state = SEED)))\n",
    "models.append(('MLP', MLPClassifier( random_state = SEED, max_iter=1000)))\n",
    "models.append(('RID', RidgeClassifier(random_state = SEED)))\n",
    "models.append(('log', LogisticRegression(random_state = SEED)))\n",
    "models.append(('SOLS', SOLSClassifier(0.745, est_method = 'mean')))\n",
    "models.append(('Pipe', Pipeline([  ('kBest', SelectKBest( f_classif,k = k)), ('ols', ols_m)])))\n",
    "\n",
    "\n",
    "# test and plot all models in models list\n",
    "def test_models(models, data, target):\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'accuracy'\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits=5, random_state=SEED)\n",
    "        cv_results = cross_val_score(model, data, target, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        #classification_metrics(y_val, rfc_pred)\n",
    "\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#run test    \n",
    "test_models(models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols_mod = SOLSClassifier(0.745, est_method = 'mean')\n",
    "sols_mod.fit(X, y)\n",
    "final_submit = sols_mod.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(final_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final array*************************************************************************************\n",
    "PassengerId =np.array(test[\"PassengerId\"]).astype(int)\n",
    "my_solution = pd.DataFrame(final_submit, PassengerId, columns = [\"Survived\"])\n",
    "\n",
    "my_solution.to_csv(\"solution_SOLSClass_oldData_1.csv\", index_label = [\"PassengerId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score\n",
    ">0.77990 Previous best Score of 0.80861 with ExtraTrees on old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
